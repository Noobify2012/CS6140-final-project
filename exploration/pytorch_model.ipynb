{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from final_project.models import FeedForward\n",
    "from final_project import builder\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from final_project.loader import get_df\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq(title, data):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,3))\n",
    "    bars = ax.bar(['delayed' if x==1 else 'on time' for x in data[0]], data[1])\n",
    "\n",
    "    ax.set_title(f'Class Instances in {title.capitalize()} Dataset')\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_ylabel('Labels')\n",
    "\n",
    "    print(data[1])\n",
    "    ax.bar_label(bars, data[1])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Show the chart\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Quarter  DayOfWeek  FlightDate Marketing_Airline_Network  \\\n",
      "0        1          2  2018-01-23                        DL   \n",
      "1        1          3  2018-01-24                        DL   \n",
      "2        1          4  2018-01-25                        DL   \n",
      "3        1          5  2018-01-26                        DL   \n",
      "4        1          6  2018-01-27                        DL   \n",
      "\n",
      "  Operated_or_Branded_Code_Share_Partners  DOT_ID_Marketing_Airline  \\\n",
      "0                            DL_CODESHARE                     19790   \n",
      "1                            DL_CODESHARE                     19790   \n",
      "2                            DL_CODESHARE                     19790   \n",
      "3                            DL_CODESHARE                     19790   \n",
      "4                            DL_CODESHARE                     19790   \n",
      "\n",
      "  IATA_Code_Marketing_Airline  Flight_Number_Marketing_Airline  \\\n",
      "0                          DL                             3298   \n",
      "1                          DL                             3298   \n",
      "2                          DL                             3298   \n",
      "3                          DL                             3298   \n",
      "4                          DL                             3298   \n",
      "\n",
      "  Originally_Scheduled_Code_Share_Airline  \\\n",
      "0                                       0   \n",
      "1                                       0   \n",
      "2                                       0   \n",
      "3                                       0   \n",
      "4                                       0   \n",
      "\n",
      "   DOT_ID_Originally_Scheduled_Code_Share_Airline  ... Dest_TYS  Dest_UIN  \\\n",
      "0                                             0.0  ...        0         0   \n",
      "1                                             0.0  ...        0         0   \n",
      "2                                             0.0  ...        0         0   \n",
      "3                                             0.0  ...        0         0   \n",
      "4                                             0.0  ...        0         0   \n",
      "\n",
      "   Dest_USA Dest_VLD Dest_VPS  Dest_WRG  Dest_XNA  Dest_YAK  Dest_YKM Dest_YNG  \n",
      "0         0        0        0         0         0         0         0        0  \n",
      "1         0        0        0         0         0         0         0        0  \n",
      "2         0        0        0         0         0         0         0        0  \n",
      "3         0        0        0         0         0         0         0        0  \n",
      "4         0        0        0         0         0         0         0        0  \n",
      "\n",
      "[5 rows x 744 columns]\n"
     ]
    }
   ],
   "source": [
    "master_df = get_df(file=\"Flights_2018_1.csv\")\n",
    "# builder.runEDA(master_df)\n",
    "master_df = builder.encodeFrame(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "process data for training, split into test/train/validation\n",
    "'''\n",
    "X = master_df.drop(columns=[\"ArrDel15\"])\n",
    "y = master_df[[\"ArrDel15\"]]\n",
    "y = y.ArrDel15.ravel() # flatten\n",
    "print(\"# samples:\", y.shape[0])\n",
    "\n",
    "# split into train and test/validation (which is then split in next line)\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=150)\n",
    "\n",
    "# create validation and test sets each 15% of total data\n",
    "X_test, X_validation, y_test, y_validation = train_test_split(X_test_val, y_test_val,\n",
    "                                                    test_size=0.5,\n",
    "                                                    random_state=150)\n",
    "data = {\"train\": (X_train,y_train), \"test\":(X_test,y_test), \"validation\": (X_validation,y_validation)}\n",
    "\n",
    "# number of classes, number of instances in each class\n",
    "for each in data.keys():\n",
    "    print(f\"{each}:\")\n",
    "    print(\" - Number of features: \", len(data[each][0].columns))\n",
    "    print(\" - Number of samples: \", len(data[each][0]))\n",
    "    unique, counts = np.unique(data[each][1], return_counts=True)\n",
    "    plot_freq(each, (unique, counts))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train numpy arrays\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "X_validation = X_validation.to_numpy()\n",
    "\n",
    "# convert to tensors\n",
    "X_train, y_train, X_test, y_test, X_validation, y_validation = map(\n",
    "    torch.tensor, (X_train, y_train, X_test, y_test, X_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloader\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "valid_ds = TensorDataset(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "num_features = X_train.shape[1]\n",
    "classes = y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exhaustive hyperparameter tuning based on the best final validation loss\n",
    "def ffn_tune(num_hidden_layers, num_nodes, param_dict):\n",
    "    best_model = {key:param_dict[key] for key in param_dict}\n",
    "    best_model[\"best_loss\"] = 100000000000\n",
    "    for bs in param_dict[\"bs\"]:\n",
    "        for epoch in param_dict[\"epoch\"]:\n",
    "            for lr in param_dict[\"learning_rate\"]:\n",
    "                # use validation loss\n",
    "                model = FeedForward(num_hidden_layers, num_nodes, num_features)\n",
    "                training_losses, valid_losses = model.fit(train_ds, valid_ds, bs, epoch, loss_function, lr)\n",
    "                if valid_losses[-1] < best_model[\"best_loss\"]:\n",
    "                    best_model[\"model\"]=model\n",
    "                    best_model[\"best_loss\"] = valid_losses[-1]\n",
    "                    best_model[\"epoch\"] = epoch\n",
    "                    best_model[\"learning_rate\"] = lr\n",
    "                    best_model[\"bs\"] = bs\n",
    "                    best_model[\"valid_losses\"] = valid_losses\n",
    "                    best_model[\"training_losses\"] = training_losses\n",
    "                print(\"best loss: \", best_model[\"best_loss\"])\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffn_evaluate(model):\n",
    "# plot losses\n",
    "    plt.plot(model[\"training_losses\"], label=\"Training Loss\")\n",
    "    # print(model[\"training_losses\"])\n",
    "    plt.plot(model[\"valid_losses\"], label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # calculate accuracy\n",
    "    d = {\"train\": train_ds, \"test\": test_ds, \"validation\": valid_ds}\n",
    "    for dataset in d:\n",
    "        print(f\"Evaluating **{dataset}** dataset:\")\n",
    "        mean_accuracy, class_accuracy, classifier_scores, confusion_matrix = model[\"model\"].score(d[dataset], model[\"bs\"])\n",
    "        print(f\"Mean Accuracy: {mean_accuracy*100:.3f}\")\n",
    "        print(f\"Mean per-class accuracy:\")\n",
    "        for key in class_accuracy:\n",
    "            print(f\"  {'delayed' if key==1 else 'on time'}{': '}{class_accuracy[key]*100:.3f}%\")\n",
    "        print(f\"Precision: {classifier_scores[0]}\")\n",
    "        print(f\"Recall: {classifier_scores[1]}\")\n",
    "        print(f\"F-Beta Score: {classifier_scores[2]}\")\n",
    "        print(f\"F1 Score: {classifier_scores}\")\n",
    "        print(confusion_matrix)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model tuning and evaluation on the 4 combos of layers/nodes\n",
    "def run_model(num_layers: int, num_nodes: int):\n",
    "    params = {\"bs\":(64,),\n",
    "            \"epoch\":(50,),\n",
    "            \"learning_rate\":(.01,)}\n",
    "    print(f\"{num_nodes} Nodes, {num_layers} Hidden Layer(s)\")\n",
    "    best_model = ffn_tune(num_layers,num_nodes, params)\n",
    "    print(\"best batch size: \", best_model[\"bs\"])\n",
    "    print(\"best epoch: \", best_model[\"epoch\"])\n",
    "    print(\"best learning rate: \", best_model[\"learning_rate\"])\n",
    "    ffn_evaluate(best_model)\n",
    "\n",
    "    # TODO save model\n",
    "    # state = best_model[\"model\"].state_dict() # save the model\n",
    "\n",
    "for pair in [(1,4)]:\n",
    "    run_model(pair[0],pair[1])\n",
    "\n",
    "# bs, epoch, learning_rate, momentum, activation function, number layers, number of nodes per hidden layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
